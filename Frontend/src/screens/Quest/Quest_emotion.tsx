import { Text, View, Alert, Image } from 'react-native';
import { useEffect, useState, useRef } from 'react';
import { Camera, useCameraDevice, useFrameProcessor } from 'react-native-vision-camera';
import { Face, useFaceDetector } from 'react-native-vision-camera-face-detector';
import { Worklets } from 'react-native-worklets-core';

import { useLoadEmotionModel } from '../../hooks/useLoadEmotionModel';
import { shouldCaptureFace } from '../../utils/faceChecker';
import { EmotionModelRunner } from '../../utils/EmotionModelRun';
import { QUESTS } from '../../utils/QuestEmotion/quests';

import EmotionChartBox from '../../components/Quest_emotionBox';
import styles from '../../styles/questEmotionStyles';
import {NavigationProp, useNavigation, useRoute} from "@react-navigation/native";
import customAxios from "../../API/axios";
import { getCoupon } from "../../API/potAPI";

type RouteParams = {
    questTitle: string;
    questDescription: string;
    questTarget: number;
    nickname: string,
};

export default function QuestEmotion() {
    const navigation = useNavigation<NavigationProp<any>>();
    const route = useRoute();
    const { questTitle, questDescription, nickname } =
        route.params as RouteParams;
    const [emotionLog, setEmotionLog] = useState<string[]>([]);
    const device = useCameraDevice('front');
    const cameraRef = useRef<any>(null);
    const { detectFaces } = useFaceDetector();
    const [hasPermission, setHasPermission] = useState(false);
    const { isLoaded, model } = useLoadEmotionModel();
    const [noFaceWarning, setNoFaceWarning] = useState(false);
    const [photoPath, setPhotoPath] = useState<string | null>(null);
    const [latestResult, setLatestResult] = useState<number[] | null>(null);
    const [success, setSuccess] = useState<boolean>(false);
    const lastPhotoTimeRef = useRef(0);
    const isPhotoTaken = useRef(false);

    const handleComplete = async () => {
        try {
            const type = "EMOTION";
            const response = await customAxios.get(`/quests/last/${type}`);
            const lastDataID = response.data.data.id;
    
            const postRes = await customAxios.post("/quests", {
                id: lastDataID,
                current: 0,
                status: "COMPLETED",
            });
    
            if (postRes.status === 200 || postRes.status === 201) {
                await getCoupon();
                Alert.alert("ì™„ë£Œ!", "ê°ì • í€˜ìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆì–´ìš”! ğŸ‰", [
                    {
                        text: "í™•ì¸",
                        onPress: () =>
                            navigation.navigate("Quest_stage", {
                                title: `${nickname}ì˜ ìˆ²`,
                            }),
                    },
                ]);
            } else {
                Alert.alert("ì˜¤ë¥˜", "ê°ì • í€˜ìŠ¤íŠ¸ ì™„ë£Œ ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.");
            }
        } catch (error) {
            console.error("ê°ì • í€˜ìŠ¤íŠ¸ ì™„ë£Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", error);
            Alert.alert("ì˜¤ë¥˜", "ì„œë²„ í†µì‹  ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.");
        }
    };  

    const quest = QUESTS.find(q => q.id === questTitle);
    const quest_capture_interval = quest?.interval ?? 1000;
    const quest_save_pre_log = quest?.logLength ?? 20;

const capturePhoto = async (face: Face | undefined): Promise<string | null> => {
    if (isPhotoTaken.current) {
        console.log("ğŸ“· ìº¡ì²˜ ê±´ë„ˆëœ€: ì´ì „ ìº¡ì²˜ ì¤‘");
        return null;
    }
    isPhotoTaken.current = true;

    const now = Date.now();
    const { isLargeEnough, now: checkedTime } = shouldCaptureFace(face, lastPhotoTimeRef.current);
    if (!isLargeEnough || now - lastPhotoTimeRef.current < quest_capture_interval) {
        isPhotoTaken.current = false;
        console.log("ğŸ“ ì–¼êµ´ì´ ì‘ê±°ë‚˜ ìº¡ì²˜ ê°„ê²© ë¯¸ë‹¬");
        return null;
    }

    try {
        const photo = await cameraRef.current.takePhoto();
        const path = `file://${photo.path}?ts=${Date.now()}`; // ê³ ìœ  URI ì²˜ë¦¬
        console.log("ğŸ“¸ ìº¡ì²˜ ì„±ê³µ:", path);
        setPhotoPath(path);
        lastPhotoTimeRef.current = checkedTime;

        // ìµœì†Œ ìº¡ì²˜ ê°„ê²© ë³´ì¥ (ì˜ˆ: 1ì´ˆ)
        setTimeout(() => {
            isPhotoTaken.current = false;
        }, 1000);
        return path;
    } catch (err) {
        console.error("âŒ ì‚¬ì§„ ìº¡ì²˜ ì‹¤íŒ¨:", err);
        isPhotoTaken.current = false;
        return null;
    }
};

    const handleDetectedFaces = Worklets.createRunOnJS(async (faces: Face[]) => {
    if (!faces?.length) {
        setNoFaceWarning(true);
        return;
    }
    setNoFaceWarning(false);

    if (!isLoaded || !model) {
        console.log("âŒ ëª¨ë¸ ë¡œë“œ ì•ˆë¨");
        return;
    }

    const face = faces[0];
    const uri = await capturePhoto(face);
    if (!uri) {
        console.log("ğŸ“› ì‚¬ì§„ ìº¡ì²˜ ì‹¤íŒ¨ or ìƒëµë¨");
        return;
    }

    const result = await EmotionModelRunner(uri, model);

    if (result) {
        const labels = ["Happy", "Surprise", "Angry", "Sad", "Disgust", "Fear", "Neutral"];
        const topIndex = result.indexOf(Math.max(...result));
        const predictedLabel = labels[topIndex];

        console.log("ğŸ¯ ì˜ˆì¸¡ ê°ì •:", predictedLabel);
        console.log(result);

        const updated = [...emotionLog, predictedLabel];
        if (updated.length > quest_save_pre_log) updated.shift();

        setEmotionLog(updated);
        setLatestResult(Array.from(result)); // âœ… ê·¸ëŒ€ë¡œ ì‚¬ìš©

        if (quest && quest.check(updated)) {
            setSuccess(true);
            console.log("âœ… í€˜ìŠ¤íŠ¸ ì¡°ê±´ ì¶©ì¡±!");
            handleComplete();
        }
    } else {
        console.warn("âš ï¸ ëª¨ë¸ ê²°ê³¼ ì—†ìŒ");
    }
});


    const frameProcessor = useFrameProcessor((frame) => {
        "worklet";
        const now = Date.now();
        const last = (globalThis as any).lastProcessTime ?? 0;
        if (now - last < quest_capture_interval) return;
        (globalThis as any).lastProcessTime = now;

        const faces = detectFaces(frame);
        handleDetectedFaces(faces);
    }, [handleDetectedFaces]);

    useEffect(() => {
        (async () => {
            const status = await Camera.requestCameraPermission();
            setHasPermission(status === 'granted');
        })();
    }, []);

    if (!device || !hasPermission) {
        return (
            <View style={styles.centered}>
                <Text>ğŸ“· ì¹´ë©”ë¼ ì¤€ë¹„ ì¤‘...</Text>
            </View>
        );
    }

    if (!quest) {
        return (
            <View style={styles.centered}>
                <Text>âŒ í€˜ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤</Text>
            </View>
        );
    }

    return (
        <View style={styles.container}>
            <View style={[styles.half, { flex: 7 }]}>
                <Camera
                    ref={cameraRef}
                    style={styles.camera}
                    device={device}
                    photo
                    isActive
                    frameProcessor={frameProcessor}
                />
            </View>

            {latestResult !== null ? (
                <View style={styles.overlay}>
                    <EmotionChartBox
                        result={latestResult}
                        success={success}
                        nickname={nickname}
                        questDescription={questDescription}
                    />
                </View>
            ) : (
                <View style={styles.overlay}>
                    {noFaceWarning && (
                        <View style={styles.centered}>
                            <Text style={styles.warningText}>âš ï¸ ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤</Text>
                        </View>
                    )}
                </View>
            )}
        </View>
    );
}
