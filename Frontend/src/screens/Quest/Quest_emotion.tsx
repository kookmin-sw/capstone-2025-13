import { useEffect, useState, useRef, useCallback } from 'react';
import { Text, View, Alert } from 'react-native';
import { Camera, useCameraDevice, useFrameProcessor, Frame } from 'react-native-vision-camera';
import type { FaceDetectionOptions } from 'react-native-vision-camera-face-detector';
import { Face, useFaceDetector } from 'react-native-vision-camera-face-detector';
import { Worklets } from 'react-native-worklets-core';

import { useLoadEmotionModel } from '../../hooks/useLoadEmotionModel';
import { shouldCaptureFace } from '../../utils/faceChecker';
import { cropFaces } from '../../plugins/cropFaces'
import { runTFLiteModelRunner } from '../../utils/EmotionModelRun';
import { QUESTS } from '../../utils/QuestEmotion/quests';

import EmotionChartBox from "../../components/Quest_emotionBox";
import styles from "../../styles/questEmotionStyles";
import {
    NavigationProp,
    useNavigation,
    useRoute,
} from "@react-navigation/native";
import customAxios from "../../API/axios";
import { getCoupon } from "../../API/potAPI";

type RouteParams = {
    questTitle: string;
    questDescription: string;
    questTarget: number;
    nickname: string;
};

export default function QuestEmotion() {
    const navigation = useNavigation<NavigationProp<any>>();
    const route = useRoute();
    const { questTitle, questDescription, nickname } =
        route.params as RouteParams;

    const [emotionLog, setEmotionLog] = useState<string[]>([]);
    const [hasPermission, setHasPermission] = useState(false);
    const [noFaceWarning, setNoFaceWarning] = useState(false);
    const [latestResult, setLatestResult] = useState<number[] | null>(null);
    const [isPredicting, setIsPredicting] = useState(false);
    const [success, setSuccess] = useState<boolean>(false);

    const device = useCameraDevice('front');
    const { isLoaded, model } = useLoadEmotionModel();
    const cameraRef = useRef<any>(null);

    const faceDetectorOptions: FaceDetectionOptions = {
      performanceMode: 'accurate',
      landmarkMode: 'none',
      contourMode: 'none',
      classificationMode: 'none',
      minFaceSize: 0.2,
      trackingEnabled: false,
      autoMode: false, // í”„ë ˆì„ ê¸°ì¤€ ì¢Œí‘œ ì‚¬ìš©
    };
    const { detectFaces } = useFaceDetector(faceDetectorOptions);

    const quest = QUESTS.find(q => q.id === questTitle);
    const quest_capture_interval = quest?.interval ?? 1000;
    const quest_save_pre_log = quest?.logLength ?? 20;
    
    const handleComplete = async () => {
        try {
            const type = "EMOTION";
            const response = await customAxios.get(`/quests/last/${type}`);
            const lastDataID = response.data.data.id;

            const postRes = await customAxios.post("/quests", {
                id: lastDataID,
                current: 0,
                status: "COMPLETED",
            });

            if (postRes.status === 200 || postRes.status === 201) {
                await getCoupon();
                Alert.alert(
                    "ì™„ë£Œ!",
                    "ê°ì • í€˜ìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆì–´ìš”! ğŸ‰",
                    [
                        {
                            text: "í™•ì¸",
                            onPress: () =>
                                navigation.navigate("Quest_stage", {
                                    title: `${nickname}ì˜ ìˆ²`,
                                }),
                        },
                    ]
                );
            } else {
                Alert.alert(
                    "ì˜¤ë¥˜",
                    "ê°ì • í€˜ìŠ¤íŠ¸ ì™„ë£Œ ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
                );
            }
        } catch (error) {
            console.error("ê°ì • í€˜ìŠ¤íŠ¸ ì™„ë£Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", error);
            Alert.alert("ì˜¤ë¥˜", "ì„œë²„ í†µì‹  ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.");
        }
    };  

    const handleFaceStatus = useCallback((hasFace: boolean) => {
        setNoFaceWarning(!hasFace);
    }, []);

   const handleDetectedResult = useCallback(
    Worklets.createRunOnJS(async (pluginResult: number[]) => {
      if (!isLoaded || !model) {
        console.log('âŒ ëª¨ë¸ ë¡œë“œ ì•ˆë¨');
        return;
      }

      if (isPredicting) {
        console.log('â³ ì˜ˆì¸¡ ì¤‘ì´ë¯€ë¡œ ìŠ¤í‚µ');
        return;
      }

      const input = new Float32Array(pluginResult);
      setIsPredicting(true);
      try {
        const result = await runTFLiteModelRunner(input, model);
        if (result) {
          const labels = ['Happy', 'Surprise', 'Angry', 'Sad', 'Disgust', 'Fear', 'Neutral'];
          const topIndex = result.indexOf(Math.max(...result));
          const predictedLabel = labels[topIndex];

          console.log('ğŸ¯ ì˜ˆì¸¡ ê°ì •:', predictedLabel);
          console.log(result);

          const updated = [...emotionLog, predictedLabel];
          if (updated.length > quest_save_pre_log) updated.shift();

          setEmotionLog(updated);
          setLatestResult(result);

          if (quest && quest.check(updated)) {
            setSuccess(true);
            console.log('âœ… í€˜ìŠ¤íŠ¸ ì¡°ê±´ ì¶©ì¡±!');
            handleComplete();
          }
        } else {
          console.warn('âš ï¸ ëª¨ë¸ ê²°ê³¼ ì—†ìŒ');
        }
      } catch (err) {
        console.error('âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜:', err);
      } finally {
        setIsPredicting(false);
      }
    }),
    [isLoaded, model, isPredicting, emotionLog, quest]
  );

  const jsHandleFaceStatus = Worklets.createRunOnJS(handleFaceStatus);
  const jsHandleDetectedResult = Worklets.createRunOnJS(handleDetectedResult);

  const frameProcessor = useFrameProcessor((frame: Frame) => {
    'worklet';

    const faces: Face[] = detectFaces(frame);
    jsHandleFaceStatus(faces.length > 0);

    if (!faces || faces.length === 0) return;

    const last = (globalThis as any).lastProcessTime ?? 0;
    const { isLargeEnough, now } = shouldCaptureFace(faces[0], last, 150, 200);
    if (!isLargeEnough) return;
    if (now - last < quest_capture_interval) return;
    (globalThis as any).lastProcessTime = now;

    const pluginResult = cropFaces(frame, faces[0].bounds) as number[];
    if (!Array.isArray(pluginResult) || typeof pluginResult[0] !== 'number') {
      console.warn('âš ï¸ Unexpected pluginResult type:', pluginResult);
      return;
    }

    const rawArray = Array.from(pluginResult);
    jsHandleDetectedResult(rawArray);
  }, [detectFaces, handleDetectedResult, quest_capture_interval]);

  useEffect(() => {
    (async () => {
      const status = await Camera.requestCameraPermission();
      setHasPermission(status === 'granted');
    })();
  }, []);

  if (!device || !hasPermission) {
    return (
      <View style={styles.centered}>
        <Text>ğŸ“· ì¹´ë©”ë¼ ì¤€ë¹„ ì¤‘...</Text>
      </View>
    );
  }

  if (!quest) {
    return (
      <View style={styles.centered}>
        <Text>âŒ í€˜ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤</Text>
      </View>
    );
  }

  return (
    <View style={styles.container}>
      <View style={[styles.half, { flex: 7 }]}>
        <Camera
          ref={cameraRef}
          style={styles.camera}
          device={device}
          photo
          isActive
          frameProcessor={frameProcessor}
        />
      </View>

      {latestResult !== null ? (
        <View style={styles.overlay}>
          <EmotionChartBox
            result={latestResult}
            success={success}
            nickname={nickname}
            questDescription={questDescription}
          />
        </View>
      ) : (
        <View style={styles.overlay}>
          {noFaceWarning && (
            <View style={styles.centered}>
              <Text style={styles.warningText}>âš ï¸ ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤</Text>
            </View>
          )}
        </View>
      )}
    </View>
  );
}