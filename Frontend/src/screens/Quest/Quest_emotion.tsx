import { StyleSheet, Text, View, Image } from 'react-native';
import { useEffect, useState, useRef } from 'react';
import { Camera, useCameraDevice, useFrameProcessor } from 'react-native-vision-camera';
import { Face, useFaceDetector } from 'react-native-vision-camera-face-detector';
import { Worklets } from 'react-native-worklets-core';

import { useLoadEmotionModel } from '../../hooks/useLoadEmotionModel';
import { shouldCaptureFace } from '../../utils/faceChecker';
import { EmotionModelRunner } from '../../utils/EmotionModelRun';
import { QUESTS } from '../../utils/QuestEmotion/quests';

import EmotionChartBox from '../../components/Quest_emotionBox';
import styles from '../../styles/questEmotionStyles';

export default function QuestEmotion() {
  const [emotionLog, setEmotionLog] = useState<string[]>([]);
  const device = useCameraDevice('front');
  const cameraRef = useRef<any>(null);
  const { detectFaces } = useFaceDetector();
  const [hasPermission, setHasPermission] = useState(false);
  const { isLoaded, model } = useLoadEmotionModel();

  const [photoPath, setPhotoPath] = useState<string | null>(null);
  const [latestResult, setLatestResult] = useState<number[] | null>(null);

  // ÌÉÄÏù¥Î∞ç Ï†úÏñ¥
  const lastPhotoTimeRef = useRef(0);
  const isPhotoTaken = useRef(false);
  
  const quest_name = '5Ï¥à Í∞Ñ ÏõÉÏñ¥Î≥¥Í∏∞';
  const quest = QUESTS.find(q => q.id === quest_name);
  if (!quest) {
    return (
      <View style={styles.centered}>
        <Text>‚ùå ÌÄòÏä§Ìä∏ Ï†ïÎ≥¥Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§</Text>
      </View>
    );
  }

  const quest_capture_interval = quest.interval ?? 1000;
  const quest_save_pre_log = quest.logLength ?? 20;

  const capturePhoto = async (face: Face | undefined) => {
    if (isPhotoTaken.current) return null;
    isPhotoTaken.current = true;

    const now = Date.now();
    const { isLargeEnough, now: checkedTime } = shouldCaptureFace(face, lastPhotoTimeRef.current);
    if (!isLargeEnough || now - lastPhotoTimeRef.current < quest_capture_interval) {
      isPhotoTaken.current = false;
      return null;
    }

    try {
      const photo = await cameraRef.current.takePhoto();
      const path = `file://${photo.path}`;
      setPhotoPath(path);
      console.log('üì∏ ÏÇ¨ÏßÑ Ï†ÄÏû•Îê®:', path);
      lastPhotoTimeRef.current = checkedTime;
      return path;
    } catch (err) {
      console.error('‚ùå ÏÇ¨ÏßÑ Ï∫°Ï≤ò Ïã§Ìå®:', err);
      return null;
    } finally {
      isPhotoTaken.current = false;
      console.log('üîÑ isPhotoTaken reset');
    }
  };

  const handleDetectedFaces = Worklets.createRunOnJS(async (faces: Face[]) => {
    if (!faces?.length || !isLoaded || !model) return;
    const face = faces[0];
    const uri = await capturePhoto(face);
    if (!uri) return;

    const result = await EmotionModelRunner(uri, model);
    if (result) {
      const labels = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral'];
      const topIndex = result.indexOf(Math.max(...result));
      const predictedLabel = labels[topIndex];
      const updated = [...emotionLog, predictedLabel];
      setLatestResult(Array.from(result));

      if (updated.length > quest_save_pre_log) updated.shift();
      setEmotionLog(updated);

      if (quest.check(updated)) {
        console.log('üéØ ÌÄòÏä§Ìä∏ ÏôÑÎ£å');
      }
    }
  });

  const frameProcessor = useFrameProcessor((frame) => {
    "worklet";
    const now = Date.now();
    const last = (globalThis as any).lastProcessTime ?? 0;
    if (now - last < quest_capture_interval) return;
    (globalThis as any).lastProcessTime = now;

    const faces = detectFaces(frame);
    handleDetectedFaces(faces);
  }, [handleDetectedFaces]);

  useEffect(() => {
    (async () => {
      const status = await Camera.requestCameraPermission();
      setHasPermission(status === 'granted');
    })();
  }, []);

  if (!device || !hasPermission) {
    return (
        <View style={styles.centered}>
          <Text>üì∑ Ïπ¥Î©îÎùº Ï§ÄÎπÑ Ï§ë...</Text>
        </View>
      );
    }

  return (
    <View style={styles.container}>
      <View style={styles.half}>
        <Camera
          ref={cameraRef}
          style={styles.camera}
          device={device}
          photo
          isActive
          frameProcessor={frameProcessor}
        />
      </View>

      <View style={[styles.half, styles.bottom]}>
        {latestResult && <EmotionChartBox result={latestResult} />}
      </View>
    </View>
  );
}
