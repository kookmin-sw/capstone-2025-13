import { Text, View, Alert, Image } from 'react-native';
import { useEffect, useState, useRef } from 'react';
import { Camera, useCameraDevice, useFrameProcessor } from 'react-native-vision-camera';
import { Face, useFaceDetector } from 'react-native-vision-camera-face-detector';
import { Worklets } from 'react-native-worklets-core';

import { useLoadEmotionModel } from './hooks/useLoadEmotionModel';
import { shouldCaptureFace } from './utils/faceChecker';
import { EmotionModelRunner } from './utils/EmotionModelRun';
import { QUESTS } from './utils/QuestEmotion/quests';

import EmotionChartBox from './components/Quest_emotionBox';
import styles from './styles/questEmotionStyles';

// í…ŒìŠ¤íŠ¸ìš© í•˜ë“œì½”ë”© íŒŒë¼ë¯¸í„°
const questTitle = "5ì´ˆ ê°„ ì›ƒì–´ë³´ê¸°";
const questDescription = "5ì´ˆ ë™ì•ˆ ì›ƒê¸°";
const nickname = "êµ­ë¯¼ì´";

export default function QuestEmotion() {
    const [emotionLog, setEmotionLog] = useState<string[]>([]);
    const device = useCameraDevice('front');
    const cameraRef = useRef<any>(null);
    const { detectFaces } = useFaceDetector();
    const [hasPermission, setHasPermission] = useState(false);
    const { isLoaded, model } = useLoadEmotionModel();
    const [noFaceWarning, setNoFaceWarning] = useState(false);
    const [photoPath, setPhotoPath] = useState<string | null>(null);
    const [latestResult, setLatestResult] = useState<number[] | null>(null);
    const [success, setSuccess] = useState<boolean>(false);
    const lastPhotoTimeRef = useRef(0);
    const isPhotoTaken = useRef(false);

    // í€˜ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œì€ Hook ì•„ë˜ì—ì„œ
    const quest = QUESTS.find(q => q.id === questTitle);
    const quest_capture_interval = quest?.interval ?? 1000;
    const quest_save_pre_log = quest?.logLength ?? 20;

    const handleComplete = async () => {
        // ì„œë²„ ì—°ë™ ì œê±°, í…ŒìŠ¤íŠ¸ ì•Œë¦¼ë§Œ
        Alert.alert("ì™„ë£Œ!", "ê°ì • í€˜ìŠ¤íŠ¸ ì™„ë£Œ (ì„œë²„ ìƒëµ)");
    };

const capturePhoto = async (face: Face | undefined): Promise<string | null> => {
    if (isPhotoTaken.current) {
        console.log("ğŸ“· ìº¡ì²˜ ê±´ë„ˆëœ€: ì´ì „ ìº¡ì²˜ ì¤‘");
        return null;
    }

    isPhotoTaken.current = true;

    const now = Date.now();
    const { isLargeEnough, now: checkedTime } = shouldCaptureFace(face, lastPhotoTimeRef.current);
    if (!isLargeEnough || now - lastPhotoTimeRef.current < quest_capture_interval) {
        isPhotoTaken.current = false;
        console.log("ğŸ“ ì–¼êµ´ì´ ì‘ê±°ë‚˜ ìº¡ì²˜ ê°„ê²© ë¯¸ë‹¬");
        return null;
    }

    try {
        const photo = await cameraRef.current.takePhoto();
        const path = `file://${photo.path}?ts=${Date.now()}`; // ê³ ìœ  URI ì²˜ë¦¬
        console.log("ğŸ“¸ ìº¡ì²˜ ì„±ê³µ:", path);
        setPhotoPath(path);
        lastPhotoTimeRef.current = checkedTime;

        // ìµœì†Œ ìº¡ì²˜ ê°„ê²© ë³´ì¥ (ì˜ˆ: 1ì´ˆ)
        setTimeout(() => {
            isPhotoTaken.current = false;
        }, 1000);

        return path;
    } catch (err) {
        console.error("âŒ ì‚¬ì§„ ìº¡ì²˜ ì‹¤íŒ¨:", err);
        isPhotoTaken.current = false;
        return null;
    }
};

    const handleDetectedFaces = Worklets.createRunOnJS(async (faces: Face[]) => {
    if (!faces?.length) {
        setNoFaceWarning(true);
        return;
    }
    setNoFaceWarning(false);

    if (!isLoaded || !model) {
        console.log("âŒ ëª¨ë¸ ë¡œë“œ ì•ˆë¨");
        return;
    }

    const face = faces[0];
    const uri = await capturePhoto(face);
    if (!uri) {
        console.log("ğŸ“› ì‚¬ì§„ ìº¡ì²˜ ì‹¤íŒ¨ or ìƒëµë¨");
        return;
    }

    const result = await EmotionModelRunner(uri, model);

    if (result) {
        const labels = ["Happy", "Surprise", "Angry", "Sad", "Disgust", "Fear", "Neutral"];
        const topIndex = result.indexOf(Math.max(...result));
        const predictedLabel = labels[topIndex];

        console.log("ğŸ¯ ì˜ˆì¸¡ ê°ì •:", predictedLabel);
        console.log(result);

        const updated = [...emotionLog, predictedLabel];
        if (updated.length > quest_save_pre_log) updated.shift();

        setEmotionLog(updated);
        setLatestResult(Array.from(result)); // âœ… ê·¸ëŒ€ë¡œ ì‚¬ìš©

        if (quest && quest.check(updated)) {
            setSuccess(true);
            console.log("âœ… í€˜ìŠ¤íŠ¸ ì¡°ê±´ ì¶©ì¡±!");
            handleComplete();
        }
    } else {
        console.warn("âš ï¸ ëª¨ë¸ ê²°ê³¼ ì—†ìŒ");
    }
});


    const frameProcessor = useFrameProcessor((frame) => {
        "worklet";
        const now = Date.now();
        const last = (globalThis as any).lastProcessTime ?? 0;
        if (now - last < quest_capture_interval) return;
        (globalThis as any).lastProcessTime = now;

        const faces = detectFaces(frame);
        handleDetectedFaces(faces);
    }, [handleDetectedFaces]);

    useEffect(() => {
        (async () => {
            const status = await Camera.requestCameraPermission();
            setHasPermission(status === 'granted');
        })();
    }, []);

    if (!device || !hasPermission) {
        return (
            <View style={styles.centered}>
                <Text>ğŸ“· ì¹´ë©”ë¼ ì¤€ë¹„ ì¤‘...</Text>
            </View>
        );
    }

    if (!quest) {
        return (
            <View style={styles.centered}>
                <Text>âŒ í€˜ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤</Text>
            </View>
        );
    }

    return (
        <View style={styles.container}>
            <View style={[styles.half, { flex: 7 }]}>
                <Camera
                    ref={cameraRef}
                    style={styles.camera}
                    device={device}
                    photo
                    isActive
                    frameProcessor={frameProcessor}
                />
                {photoPath && (
                    <View style={{ position: 'absolute', top: 10, left: 10, width: 100, height: 100, borderWidth: 1, borderColor: '#fff' }}>
                        <Image
                        source={{ uri: photoPath }}
                        style={{ width: '100%', height: '100%', borderRadius: 8 }}
                        resizeMode="cover"
                        />
                    </View>
                    )}
            </View>

            {latestResult !== null ? (
                <View style={styles.overlay}>
                    <EmotionChartBox
                        result={latestResult}
                        success={success}
                        nickname={nickname}
                        questDescription={questDescription}
                    />
                </View>
            ) : (
                <View style={styles.overlay}>
                    {noFaceWarning && (
                        <View style={styles.centered}>
                            <Text style={styles.warningText}>âš ï¸ ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤</Text>
                        </View>
                    )}
                </View>
            )}
        </View>
    );
}
